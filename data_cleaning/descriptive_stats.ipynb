{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b105d041-a79d-4a2c-945c-9073e599068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194c9da6-065f-452f-b7cc-f43fcf1d0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview(df, file_name):\n",
    "    # Shape of data: No. of rows and columns\n",
    "    no_rows, no_cols = df.shape\n",
    "\n",
    "    # Check for missing values\n",
    "    null_values = df.isnull().sum().sum()\n",
    "\n",
    "    # No. of duplicates values\n",
    "    duplicates = df[df.duplicated()].shape[0]\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "    # Diagnostics results\n",
    "    data_check = \"\"\"\n",
    "    - The dataset {0} has {1} rows and {2} columns\n",
    "    - There are {3} null/na values and {4} duplicate rows which were removed. \n",
    "    \"\"\" \n",
    "\n",
    "    print(data_check.format(file_name, no_rows, no_cols,\n",
    "                            null_values, duplicates))\n",
    "    \n",
    "    \n",
    "#     print(\"All duplicated rows were removed\")\n",
    "    \n",
    "def loading_datasets(fold, file_names):\n",
    "    # Loading the datasets\n",
    "    datasets = []\n",
    "    for name in file_names:\n",
    "        data = pd.read_csv(fold + name)\n",
    "        # Remove those with no renewvia_id\n",
    "        data.dropna(subset=['renewvia_id'], inplace=True)\n",
    "        if 'Unnamed: 0' in data.columns:\n",
    "            data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "        overview(data, name)\n",
    "        datasets.append(data)\n",
    "        \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc5b517a-764d-4142-89c9-f7f8e215da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    - The dataset household_pre_survey_clean.csv has 1562 rows and 30 columns\n",
      "    - There are 7199 null/na values and 4 duplicate rows which were removed. \n",
      "    \n",
      "\n",
      "    - The dataset household_post_survey_clean.csv has 2602 rows and 40 columns\n",
      "    - There are 14045 null/na values and 12 duplicate rows which were removed. \n",
      "    \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_clean/commercial_post_survey_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m surveys_clean \u001b[38;5;241m=\u001b[39m loading_datasets(fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_clean/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                                  file_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousehold_pre_survey_clean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhousehold_post_survey_clean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommercial_post_survey_clean.csv\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36mloading_datasets\u001b[0;34m(fold, file_names)\u001b[0m\n\u001b[1;32m     27\u001b[0m datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[0;32m---> 29\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fold \u001b[38;5;241m+\u001b[39m name)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Remove those with no renewvia_id\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     data\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrenewvia_id\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_clean/commercial_post_survey_clean.csv'"
     ]
    }
   ],
   "source": [
    "surveys_clean = loading_datasets(fold='data_clean/',\n",
    "                                 file_names = ['household_pre_survey_clean.csv', \n",
    "                                              'household_post_survey_clean.csv',\n",
    "                                              'commercial_post_survey_clean.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fff4f3-ec9d-4688-af12-acbab44805ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'surveys_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hs_post \u001b[38;5;241m=\u001b[39m surveys_clean[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m hs_post\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'surveys_clean' is not defined"
     ]
    }
   ],
   "source": [
    "hs_post = surveys_clean[1]\n",
    "hs_post.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e62cc-8a21-49dd-9211-054074196588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_autopct(values):\n",
    "    def my_autopct(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{v:d} ({p:.2f}%)'.format(p=pct,v=val)\n",
    "    return my_autopct\n",
    "\n",
    "# Has there been a change in the number of females in your household \n",
    "# who attend school full time since connection to minigrid power?\n",
    "\n",
    "# Has there been a change in the number of males in your household \n",
    "# who attend school FULL TIME since connection to minigrid power?\n",
    "\n",
    "cols = ['female_schooling_change', 'male_schooling_change']\n",
    "var_freq = {}\n",
    "for col in cols:\n",
    "    labels = hs_post[col].value_counts(dropna=True).index\n",
    "    vals = hs_post[col].value_counts(dropna=True).values\n",
    "    var_freq[col] = [vals, labels]\n",
    "\n",
    "# # Proportions by seat type\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 10))\n",
    "fig.suptitle(\"Change in School Attendance Per Gender\", \n",
    "             y=0.8, fontsize=30, fontweight='bold'\n",
    "            )\n",
    "ax1.pie(var_freq[cols[0]][0], labels=var_freq[cols[0]][1], autopct=make_autopct(vals))\n",
    "ax1.set_title('Female Children')\n",
    "ax2.pie(var_freq[cols[1]][0], labels=var_freq[cols[1]][1], autopct=make_autopct(vals))\n",
    "ax2.set_title(\"Male Children\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a60450-76e4-4edb-a06c-1dc6afda3a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you answered yes to adding new workers, how many new employees are female?\n",
    "# Are any household members business owners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce038e6-ef4f-4d66-bf59-86c519f26d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df_post['household_business_owners'].describe())\n",
    "# df_post['household_business_owners'].value_counts(normalize=True)\n",
    "\n",
    "# # Unique value counts for categorical columns\n",
    "# for col in df.columns[2:]:\n",
    "#     print(col)\n",
    "#     col_cats_count = df[col].value_counts(sort=True)\n",
    "#     n_cat = len(col_cats_count.keys())\n",
    "#     freq = dict(col_cats_count)\n",
    "#     if n_cat <= 10:\n",
    "#         print(n_cat)\n",
    "#         print(freq)\n",
    "#     else:\n",
    "#         print(n_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
